# De SoÃ±ar con Bicicletas a Construir un Modelo de Machine Learning + Fintech ğŸš´â€â™‚ï¸ğŸ¤–

Hace poco estuve curioseando sobre futuras bicicletas. Me fijÃ© en lo que cada vez se ve mÃ¡s en productos asÃ­: opciones de financiaciÃ³n ğŸ’¸, las cuales me parecÃ­an muy tentadoras. Aunque por ahora he resistido la tentaciÃ³n, me picÃ³ la curiosidad: cuando pinchas la opciÃ³n de financiaciÃ³n y te evalÃºan para decidir si darte el prÃ©stamo o no, Â¿quÃ© estarÃ¡ pasando por detrÃ¡s? ğŸ¤” Seguro que es un modelo de aprendizaje automÃ¡tico.

Para investigar, pensÃ© que serÃ­a interesante crear mi propio modelo. EncontrÃ© un dataset con informaciÃ³n detallada sobre solicitudes de prÃ©stamo (disponible en mi GitHub).

## AnÃ¡lisis Exploratorio ğŸ”
Lo primero fue realizar un anÃ¡lisis exploratorio para entender los datos y asegurarme de que estaban limpios. ObservÃ© las distribuciones de cada variable y notÃ© que la variable objetivo (loan_status) estaba desequilibrada, con un 85% de las instancias como rechazos âŒ. Esto hacÃ­a necesario estratificar los datos al dividirlos en entrenamiento y prueba.
Durante este anÃ¡lisis univariante, tambiÃ©n notÃ© que las variables numÃ©ricas tenÃ­an escalas muy diferentes ğŸ“, algo que requerirÃ­a estandarizaciÃ³n para modelos lineales. ExplorÃ© las variables categÃ³ricas con pandas.value_counts() para comprender mejor sus distribuciones y preparar su codificaciÃ³n posterior.

En el anÃ¡lisis bivariante, evaluÃ© relaciones entre las variables predictoras y el objetivo. DescubrÃ­ que dos variables numÃ©ricas mostraban una relaciÃ³n mÃ¡s clara con el objetivo cuando se combinaban. Esto me llevÃ³ a crear una nueva variable: loan_amnt_times_percent_income, que resultÃ³ ser muy predictiva.
TambiÃ©n analicÃ© las variables categÃ³ricas con grÃ¡ficos de barras ğŸ“Š y descubrÃ­ patrones interesantes, como la fuerte relaciÃ³n entre loan_grade y los resultados de los prÃ©stamos.

## PreparaciÃ³n de Datos ğŸ› ï¸
EstandaricÃ© las variables numÃ©ricas con un StandardScaler para garantizar que todas tuvieran la misma escala, algo crucial para modelos lineales. DespuÃ©s, separÃ© los datos en conjuntos de entrenamiento y prueba, cuidando de evitar data leakage y de mantener la proporciÃ³n del objetivo mediante estratificaciÃ³n.

## Modelos y Resultados ğŸ¤–
ComencÃ© con un modelo de Logistic Regression utilizando solo tres variables:

loan_int_rate
loan_percent_income
loan_amnt_times_percent_income

### Este modelo logrÃ³ un ROC AUC de 86%.
Â¿QuÃ© es ROC AUC? Representa el Ã¡rea bajo la curva que relaciona la tasa de verdaderos positivos (recall) y la tasa de falsos positivos a diferentes umbrales de clasificaciÃ³n. Un 100% indica un modelo que siempre clasifica bien, mientras que un 50% serÃ­a como adivinar al azar ğŸ¯. Es un indicador especialmente Ãºtil en problemas con clases desbalanceadas, como este caso.

Entusiasmado por los resultados, probÃ© un modelo mÃ¡s avanzado basado en Gradient Boosting (XGBoost). Usando validaciÃ³n cruzada estratificada con 10 divisiones, logrÃ© un ROC AUC promedio de 89%. Finalmente, optimicÃ© el modelo con una bÃºsqueda aleatoria de hiperparÃ¡metros (RandomizedSearchCV) y conseguÃ­ un 90% ROC AUC, lo que considero excepcional con solo tres variables.

## Lecciones y PrÃ³ximos Pasos ğŸš€
Una gran ventaja de estos modelos es su interpretabilidad. Esto es valioso para empresas fintech ğŸ¦, ya que permite explicar a los clientes por quÃ© su solicitud fue rechazada. AdemÃ¡s, al requerir solo tres variables, este modelo simplifica enormemente el proceso de decisiÃ³n.

En cuanto a prÃ³ximos pasos, planeo incorporar mÃ¡s variables categÃ³ricas, lo que probablemente mejorarÃ¡ el rendimiento del modelo. UsarÃ© tÃ©cnicas como OneHotEncoding para representarlas de forma adecuada.

Por ahora, estoy muy satisfecho con los resultados obtenidos. Â¡Espero que te haya resultado interesante este pequeÃ±o viaje de curiosidad y aprendizaje! ğŸŒŸ


